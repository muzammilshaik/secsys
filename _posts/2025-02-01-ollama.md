---
author: muju
title: "Open WebUI & Ollama setup on Windows"
description: "A comprehensive guide to installing and configuring Open WebUI and Ollama on Windows."
categories: ["Windows"]
image:
  path: "/assets/windows/ollama/ollama1.webp"
  lqip: "data:image/webp;base64,UklGRmABAABXRUJQVlA4WAoAAAAQAAAAEwAAEwAAQUxQSBQBAAABgGPb2rHnfvj/2FU6m11S2TYGYAzAtm3btm0bpe2ksr8pRMQEkBQYUyRAODcFcPzG4d/kTACA8Uv+Q9JvCY/5L6Y/mvbp1FthNQd7FcHbdHq3GQCx1gzHj8vricnbs3cnNK0TAOaWfGrvXbgBHu+nOp+FeQDqB5eNhSb41bqg+eZAA5rPhfz4t1Dls+b0PAsMOTYG7hNAR/mShkXd3UVGpG80jeyTlVGKpz8ttVFJRESxMS11gJeem7J8CwGELviI6gKC51oQCHs19HjRBajuGFFJMdHoHgrQefEamyEAcLrWdnTUuXECIKYnNlrBuHmz5EyIidBpmfRzBZPyZ1mrNycmjm82WRdsJuzz7NRjTiach2lWUDggJgAAANACAJ0BKhQAFAA+kUSdSqWjoqGoCACwEglpAAA9o6AA/vjPGsAA"
tags: ["docker", "ollama", "open-webui"]
published: true
hidden: false
toc: true  # Table of Content
---

# üåê What is Open WebUI?

Open WebUI is an open-source, web-based user interface designed to simplify interactions with backend applications. It provides a sleek interface for handling modules, pulling resources, and managing tasks efficiently.

---

# üñ•Ô∏è System Requirements

To install and use Open WebUI and Ollama on Windows, ensure your system meets the following requirements:

- **Operating System:** Windows 10/11 (64-bit)
- **RAM:** Minimum 8GB (16GB recommended)
- **Processor:** x64-based processor
- **Storage:** At least 20GB of free space
- **Software:** Docker Desktop, Winget, or Chocolatey (for package management)

---

## 1Ô∏è‚É£ Install Ollama

Ollama is a prerequisite for running Open WebUI. Follow these steps to install it on Windows:

1. Visit the [official Ollama website](https://ollama.com) and download the installer for Windows.
2. Run the installer and follow the on-screen instructions to complete the installation.
3. Verify the installation by opening a terminal and typing:
   ```powershell
   ollama --version
   ```
![ollama](/assets/windows/ollama/ollama1.png){: width="800" height="300" }

If the version number appears, Ollama has been installed successfully.

---

## 2Ô∏è‚É£ Install Open WebUI using python

### install using [python](https://docs.openwebui.com/getting-started/quick-start#1-install-uv){:target="_blank"} 

Open the terminal as administrator and install the python 

1. Open a terminal and install Docker Desktop using **Winget**:
   ```powershell
   winget install Python.Python.3.10
   ```
   Alternatively, use **Chocolatey**:
   ```powershell
   choco install python --version=3.10
   ```   

2. Once installed, launch terminal and ensure it is running. Verify by typing:
   ```powershell
   python --version
   ```
   ![ollama](/assets/windows/ollama/ollama2.png){: width="800" height="300" }

#### Default Model Directory

By default, Ollama stores models in the following directory: `C:\Users\%username%\.ollama\models`

Steps to Change the Model Directory if needed

Follow these steps to change the model directory:
- 1. Quit Ollama: Ensure that the Ollama application is not running. You can do this by right-clicking the Ollama icon in the taskbar and selecting 'Quit'.
- 2. Open Environment Variables:
    - For Windows 11, open the Settings app and search for "environment variables".
    - For Windows 10, open the Control Panel and search for "environment variables".
- 3. Edit Environment Variables: Click on "Edit environment variables for your account".
    - Set the OLLAMA_MODELS Variable:
        - If the variable already exists, select it and click "Edit". If it does not exist, click "New" to create it.
        - Set the variable name to OLLAMA_MODELS and the value to your desired directory path (e.g., D:\OllamaModels).

- 4. Save Changes: Click OK/Apply to save your changes.
- 5. Restart Ollama: Launch the Ollama application from the Start menu to apply the new settings. 

> Reboot the system to update the environment variables 
{: .prompt-info }

#### installing open webui using python uvx

`uvx` is a command-line tool designed to manage Python environments and run Python applications easily. It simplifies version management, package installation, and application execution, especially for Python-based projects like OpenWebUI.

   ```powershell
   powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
   $env:DATA_DIR="D:\owui\data"; uvx --python 3.11 open-webui@latest serve
   ```
   
![ollama](/assets/windows/ollama/ollama3.png){: width="800" height="500" } 
![ollama](/assets/windows/ollama/ollama4.png){: width="800" height="500" }

Open your browser and navigate to [`http://localhost:8080`](http://localhost:8080){:target="_blank"} to access the Open WebUI interface.

---

### install using Docker

#### Configuring Open WebUI with Docker

As my system has s dedicated server so am using the GPU webui if you dont have a GPU you can exclude it check the official [ollama quick start guide](https://docs.openwebui.com/){:target="_blank"} 

Create a `docker-compose.yml` file with the following configuration:

```yaml
services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:cuda
    container_name: open-webui
    ports:
      - "3000:8080"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    volumes:
      - open-webui:/app/backend/data
    restart: unless-stopped
    extra_hosts:
            - 'host.docker.internal:host-gateway'
volumes:
  open-webui:
    driver: local
```

#### Key Configuration Breakdown:
- **Image:** Specifies the container image from the Open WebUI GitHub Container Registry.
- **Restart:** Ensures the container automatically restarts on failure or reboot.
- **Volumes:** Maps a directory for persistent data storage.
- **Extra Hosts:** Links the container to the host system for seamless communication.
- **Ports:** Maps the internal port `8080` to the external port `3000` for web access.

#### Running the Docker Container

1. Navigate to the directory containing the `docker-compose.yml` file.
2. Run the following command to start the Open WebUI container:
   ```powershell
   docker-compose up -d
   ```
3. Verify the container is running:
   ```powershell
   docker ps
   ```

## 3Ô∏è‚É£ Sign In to Open WebUI

1. Open the browser and go to [`http://localhost:8080`](http://localhost:8080){:target="_blank"}
2. Create an account or log in using your existing credentials.

![ollama](/assets/windows/ollama/ollama5.png){: width="600" height="300" }

---

## 4Ô∏è‚É£ Pull the Modules

Once signed in, navigate to the "Admin panel > settings > Modules" section in Open WebUI and:

### pulling the module via openwebui  
1. Select the [module](https://ollama.com/search){:target="_blank"} you wish to install.
2. Click "Pull" to download and install the module. Ensure your internet connection is stable for smooth downloads.

![ollama](/assets/windows/ollama/ollama6.png){: width="800" height="500" }

---

## 5Ô∏è‚É£ Select the Module and Enjoy the Chat

After the modules are installed:

1. Go to the "Chat" section.
2. Select your preferred module from the dropdown.
3. Start chatting and exploring the capabilities of Open WebUI!

---

# üöÄ Conclusion

By following this guide, you should now have a fully functional Open WebUI and Ollama setup on your Windows machine. With this setup, you can effortlessly manage modules, interact with backend data, and enjoy the streamlined user interface Open WebUI offers.
